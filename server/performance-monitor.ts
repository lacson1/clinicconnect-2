import { Request, Response, NextFunction } from 'express';
import { db } from './db';
import { performanceMetrics, errorLogs } from '../shared/schema';
import { eq, and, gte, desc } from 'drizzle-orm';

interface PerformanceData {
  endpoint: string;
  method: string;
  responseTime: number;
  statusCode: number;
  memoryUsage: number;
  cpuUsage: number;
  timestamp: Date;
  userId?: number;
  organizationId?: number;
}

class PerformanceMonitor {
  private metricsBuffer: PerformanceData[] = [];
  private readonly BUFFER_SIZE = 100;
  private readonly FLUSH_INTERVAL = 30000; // 30 seconds

  constructor() {
    this.startPeriodicFlush();
  }

  middleware() {
    return (req: Request, res: Response, next: NextFunction) => {
      const startTime = Date.now();
      const startMemory = process.memoryUsage();
      const startCpu = process.cpuUsage();

      // Override res.end to capture response time
      const originalEnd = res.end;
      res.end = function(chunk?: any, encoding?: any) {
        const endTime = Date.now();
        const responseTime = endTime - startTime;
        const endMemory = process.memoryUsage();
        const endCpu = process.cpuUsage(startCpu);

        // Calculate metrics
        const memoryUsage = (endMemory.heapUsed - startMemory.heapUsed) / 1024 / 1024; // MB
        const cpuUsage = (endCpu.user + endCpu.system) / 1000; // milliseconds

        // Store performance data
        const performanceData: PerformanceData = {
          endpoint: req.path,
          method: req.method,
          responseTime,
          statusCode: res.statusCode,
          memoryUsage,
          cpuUsage,
          timestamp: new Date(),
          userId: (req as any).user?.id,
          organizationId: (req as any).user?.organizationId
        };

        // Add to buffer
        monitor.addToBuffer(performanceData);

        // Check for performance issues
        monitor.checkPerformanceIssues(performanceData, req);

        originalEnd.call(this, chunk, encoding);
      };

      next();
    };
  }

  private addToBuffer(data: PerformanceData) {
    this.metricsBuffer.push(data);
    
    if (this.metricsBuffer.length >= this.BUFFER_SIZE) {
      this.flushMetrics();
    }
  }

  private async flushMetrics() {
    if (this.metricsBuffer.length === 0) return;

    try {
      const metrics = this.metricsBuffer.splice(0);
      
      await db.insert(performanceMetrics).values(
        metrics.map(metric => ({
          endpoint: metric.endpoint,
          method: metric.method,
          responseTime: metric.responseTime,
          statusCode: metric.statusCode,
          memoryUsage: metric.memoryUsage.toString(),
          cpuUsage: metric.cpuUsage.toString(),
          timestamp: metric.timestamp,
          userId: metric.userId || null,
          organizationId: metric.organizationId || null
        }))
      );

      console.log(`ðŸ“Š Performance metrics flushed: ${metrics.length} records`);
    } catch (error) {
      console.error('Failed to flush performance metrics:', error);
      // Re-add metrics to buffer for retry on next flush
      this.metricsBuffer.unshift(...metrics);
    }
  }

  private checkPerformanceIssues(data: PerformanceData, req: Request) {
    // Check for slow responses (>2 seconds)
    if (data.responseTime > 2000) {
      this.logPerformanceIssue('SLOW_RESPONSE', {
        message: `Slow response detected: ${data.endpoint} took ${data.responseTime}ms`,
        endpoint: data.endpoint,
        responseTime: data.responseTime,
        req
      });
    }

    // Check for high memory usage (>50MB per request)
    if (data.memoryUsage > 50) {
      this.logPerformanceIssue('HIGH_MEMORY_USAGE', {
        message: `High memory usage detected: ${data.memoryUsage.toFixed(2)}MB for ${data.endpoint}`,
        endpoint: data.endpoint,
        memoryUsage: data.memoryUsage,
        req
      });
    }

    // Check for 5xx errors
    if (data.statusCode >= 500) {
      this.logPerformanceIssue('SERVER_ERROR', {
        message: `Server error: ${data.statusCode} for ${data.endpoint}`,
        endpoint: data.endpoint,
        statusCode: data.statusCode,
        req
      });
    }
  }

  private async logPerformanceIssue(type: string, details: any) {
    try {
      const errorId = `perf_${Date.now()}_${Math.random().toString(36).substring(2, 15)}`;
      
      await db.insert(errorLogs).values({
        errorId,
        type: 'PERFORMANCE',
        severity: type === 'SERVER_ERROR' ? 'HIGH' : 'MEDIUM',
        message: details.message,
        url: details.endpoint,
        component: 'performance-monitor',
        userId: details.req.user?.id || null,
        organizationId: details.req.user?.organizationId || null,
        resolved: false,
        retryable: type !== 'SERVER_ERROR',
        createdAt: new Date()
      });

      console.log(`âš ï¸ Performance Issue [${errorId}]: ${details.message}`);
    } catch (error) {
      console.error('Failed to log performance issue:', error);
    }
  }

  private startPeriodicFlush() {
    setInterval(() => {
      this.flushMetrics();
    }, this.FLUSH_INTERVAL);
  }

  async getPerformanceStats(timeframe: string = '24h') {
    const timeAgo = new Date();
    switch (timeframe) {
      case '1h':
        timeAgo.setHours(timeAgo.getHours() - 1);
        break;
      case '24h':
        timeAgo.setDate(timeAgo.getDate() - 1);
        break;
      case '7d':
        timeAgo.setDate(timeAgo.getDate() - 7);
        break;
      default:
        timeAgo.setDate(timeAgo.getDate() - 1);
    }

    try {
      const metrics = await db
        .select()
        .from(performanceMetrics)
        .where(gte(performanceMetrics.timestamp, timeAgo))
        .orderBy(desc(performanceMetrics.timestamp));

      // Calculate statistics
      const totalRequests = metrics.length;
      const avgResponseTime = metrics.reduce((sum, m) => sum + m.responseTime, 0) / totalRequests || 0;
      const avgMemoryUsage = metrics.reduce((sum, m) => sum + parseFloat(m.memoryUsage as string), 0) / totalRequests || 0;
      const avgCpuUsage = metrics.reduce((sum, m) => sum + parseFloat(m.cpuUsage as string), 0) / totalRequests || 0;

      // Get slowest endpoints
      const endpointStats = metrics.reduce((acc, metric) => {
        const key = `${metric.method} ${metric.endpoint}`;
        if (!acc[key]) {
          acc[key] = { count: 0, totalTime: 0, maxTime: 0 };
        }
        acc[key].count++;
        acc[key].totalTime += metric.responseTime;
        acc[key].maxTime = Math.max(acc[key].maxTime, metric.responseTime);
        return acc;
      }, {} as Record<string, { count: number; totalTime: number; maxTime: number }>);

      const slowestEndpoints = Object.entries(endpointStats)
        .map(([endpoint, stats]) => ({
          endpoint,
          avgResponseTime: stats.totalTime / stats.count,
          maxResponseTime: stats.maxTime,
          requestCount: stats.count
        }))
        .sort((a, b) => b.avgResponseTime - a.avgResponseTime)
        .slice(0, 10);

      // Error rates (as percentage)
      const errorRate = (metrics.filter(m => m.statusCode >= 400).length / totalRequests) || 0;

      return {
        totalRequests,
        avgResponseTime: Math.round(avgResponseTime),
        avgMemoryUsage: Math.round(avgMemoryUsage * 100) / 100,
        avgCpuUsage: Math.round(avgCpuUsage * 100) / 100,
        errorRate: Math.round(errorRate * 10) / 10, // Fixed: Round to 1 decimal place
        slowestEndpoints,
        timeframe
      };
    } catch (error) {
      console.error('Failed to get performance stats:', error);
      return null;
    }
  }
}

export const monitor = new PerformanceMonitor();
export const performanceMiddleware = monitor.middleware();